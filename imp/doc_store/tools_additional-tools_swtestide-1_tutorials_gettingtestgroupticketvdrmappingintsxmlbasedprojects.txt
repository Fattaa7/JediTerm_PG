{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "tools_additional-tools_swtestide-1_tutorials_gettingtestgroupticketvdrmappingintsxmlbasedprojects.txt"}, "page_content": "[BL_60][SwTestIDE] Getting test group ticket (VDR) mapping, nonconformity table, \nSwTest dashboard in .tsxml based projects\nPost date: May 4, 2016 9:41:16 AM\nStarting from tools baseline 60 (SwTestIDE 4.95) the generated tsxml summary \ncontains also the Dimensions tickets,and CoreAlm tickets starting baseline 70\nSteps to get an automatized ticket mapping\n1.) Load your (existing) SwTestIDE project xml containing the references to the \ntsxml files\n2.) Configure the project (Dimensions/CoreAlm)  carrying the tickets opened for the \nrelated testing project\n3.) Selecting a CoreAlm project you have to provide your credentials first to be \nable to load.\n4.) The Ticket title filter regex is by default \".*\" This means that you will search\nthrough all the tickets related to the selected project.\n5.) If you want to search through a specific set of tickets, you have to provide a \nvalidregular expressionthat will be applied to every ticket title.\n3.) Use the \"Log tsxml\" button in the FlowControl\n4.) Result:\nPrecondidions for ticket mapping\nPrecondition for getting the tickets mapped to your test groups is that the related \nfields in the VDRs are correctly filled - at least the test group names have to be a\ncomma separated list:\nAffected tickets (using wildcard in TC_ID field)\nIf the ticket you are opening on Serena is affecting many test groups all with the \nsame prefix or post-fix and you don't want to write all of them --> you have to use \na wild card as shown below:\n\"Offline_PRIC_*, Full_name_of_any_test_group,\"\nThis means that the current ticket is related to any test group starting with \n\"Offline_RCWS\",the output in this case will be different:\nAdapting TC_ID field used for mapping in case of already existing tickets\nIf that is not the case make usage of the following SQL statement in ALM Client to \nget a table with all of the VDRs linked to your porject.\nJust adapt the bold sections:\nSQL Statement\nselect distinct a.ch_doc_id,b.attr_19 PRIORITY,a.create_date,a.status, a.seq\n,b.attr_84 CUSTOMER_REFERENCE,b.attr_62 IMPACTED_AREA,b.attr_101 \nDEEP_ANALYSIS,b.attr_1 TITLE,b.attr_64 PROPOSED_CHANGE,\nb.attr_59 ENVIRONMENTAL_CONDITIONS,b.attr_39 PROJECT_ID,b.attr_71 \nDESCRIPTION,b.attr_105 INTERNAL,b.attr_61 RELEASE_LABEL,b.attr_36 DUE_DATE,b.attr_86\nCOMMENT_THREAD,b.attr_83 MORE_INFO_PROVIDED,b.attr_67 \nMORE_INFO_REQUEST,--pchd.ch_doc_id P_ID,pchd.status P_STATUS,\na.action_date,a.update_date,a.ch_uid,a.ch_doc_type,a.originator,i.workset_name,\nb.attr_22 DETAILED_ANALYSIS,b.attr_88 SAMPLE_ID,b.attr_50 TARGET_RELEASE, b.attr_26 \nREJECT_REASON, b.attr_47 TC_REQ_BIS ,   b.attr_107 REQIREMENT_KEY\n, x.TESTGROUPS\nfrom pcms_chdoc_data a\njoin cm_attributes b on (b.ch_uid = a.ch_uid and b.seq=a.seq)\nleft join\n(select * from (select a2.ch_doc_id,\nLISTAGG(b2.attr_47, '') WITHIN GROUP (ORDER BY b2.seq ASC)\nTESTGROUPS\nfrom pcms_chdoc_data a2\njoin cm_attributes b2 on (b2.ch_uid = a2.ch_uid and b2.seq=a2.seq)\njoin pcms_chdoc_related_worksets relw2 on (a2.ch_uid = relw2.from_ch_uid)\njoin pcms_workset_info i2 on (relw2.to_workset_uid=i2.workset_uid)\nwhere ((i2.product_id='MBM')) and a2.ch_doc_type='VDR' -- and i2.workset_name like \n'%_FORD_XCD4%'\nGROUP BY a2.ch_doc_id)\n) x on (a.ch_doc_id=x.ch_doc_id)\njoin pcms_chdoc_related_parts crp on (crp.from_ch_uid = a.ch_uid)\njoin pcms_part_data p on (p.part_uid = crp.to_part_uid) --  and \n(p.part_id='FORD_XCD4_2_PROJECT'))\njoin pcms_chdoc_related_worksets relw on (a.ch_uid = relw.from_ch_uid)\njoin pcms_workset_info i on (relw.to_workset_uid=i.workset_uid\nand ((i.product_id='MBM' ))) where a.seq=1 and i.workset_name like '%AP_79GHZ_DEV%'\nand a.ch_doc_type='VDR'\nThe result table contains all the tickets linked to your project.  Look at \ntheTESTGROUPS columnto identify the tickets that are nothaving a comma separated \nlistin theTC IDfield. right click the entry and say \"edit attributes\" and correct \nthe entry. After that click save. Please note that there are specific rights needed \nto be allowed to do that.\nIt is recommended to also correct the requirement link - following the format \ndefined for the tsxml requirementkex xml node.\nTsxml summary generator feature upgrade using SwTestIDE 4.90 (BL 60)\nPlease be aware that the old x.ls summary generated by previous versions of the \nswTestIDE can't be automatically updated to the new style - instead please start a \nnew file - SwTestIDE will now also automatically add the reqired macro for \nvisualization.\nSwTest Regression Statistic Sheet:\nSelect row 6 and enable Filter in Excel (Data -> Filter). Row 5 shows the numbers \nafter applying the filter you have selected.\n(In this sample the user wants to see all not tested test groups from the last \nregression run (15.7.16) which are having linked tickets)\nTracability Sheet (per regression loop) :\nUse this e.g. for checking the inluence of requirement changes to the test groups.\nSwTest Cockpit Chart (Representing a 100% automatized snapshot of the SwTest project\nKPIs) :\nNumber of Testcases total, passed, not OK, not tested\nNumber of Testcases total, passed, not OK, not tested\nNumber of Testseries total, passed, not OK, not tested\nNumber of Testseries total, passed, not OK, not tested\nNumber of Testsubseries total, passed, not OK, not testedNumber of Tickets per group\npending on development (green), pending on testing (red), not tested tickets \n(white)Requirement robustness (if e.g. a requirement is passing at one point but \nfailing at another then the trustability for that requirement is 50% - this ratio is\ncalculated for all requirements. The average is considered as requirements \nrobustness, the values says something about the quality of the requirement \nreferences done in the test models and also about the quality of the requirements \nthemselves - values below 89% should be seen as hint to work on SRS and or \nrequirement mapping in the test models)Tracability - > planned to be filled with the\ncoverage calculated by linking (based on the Doors extracts generated by Doors \nImporter ->Under ConstructionTrend analysis for tickets and passed test units\nNumber of Testsubseries total, passed, not OK, not tested\nNumber of Tickets per group pending on development (green), pending on testing \n(red), not tested tickets (white)\nNumber of Tickets per group pending on development (green), pending on testing \n(red), not tested tickets (white)\nRequirement robustness (if e.g. a requirement is passing at one point but failing at\nanother then the trustability for that requirement is 50% - this ratio is calculated\nfor all requirements. The average is considered as requirements robustness, the \nvalues says something about the quality of the requirement references done in the \ntest models and also about the quality of the requirements themselves - values below\n89% should be seen as hint to work on SRS and or requirement mapping in the test \nmodels)\nRequirement robustness (if e.g. a requirement is passing at one point but failing at\nanother then the trustability for that requirement is 50% - this ratio is calculated\nfor all requirements. The average is considered as requirements robustness, the \nvalues says something about the quality of the requirement references done in the \ntest models and also about the quality of the requirements themselves - values below\n89% should be seen as hint to work on SRS and or requirement mapping in the test \nmodels)\nTracability - > planned to be filled with the coverage calculated by linking (based \non the Doors extracts generated by Doors Importer ->Under Construction\nTracability - > planned to be filled with the coverage calculated by linking (based \non the Doors extracts generated by Doors Importer ->Under Construction\nTrend analysis for tickets and passed test units\nTrend analysis for tickets and passed test units\nGenerating nonconformity table for SwTestPlanSpecReport\nThe template for the SwTestSummary generated by SwTestIDE contains starting from BL \nLM_SNP_DEVELOPMENT_BUILT_TOOLS_060_008 a macro togenerate the none conformities \ntableneeded for the SwTestPlanSpec Report. The template for the summary is located \nin the baseline here:\nLM_SW_TEST_CASTLE_TOOLS_060\\VB\\bin\\SwTestIDE\\Templates\\SwTestSummary.xls and gets \nautomatically used by SwTestIDE if a new summary shall be generated.\nStep1 (after generating the Summary) - run the embedded macro:\nIf the Excel Dedeloper menue is not shown then check this option:\nStep2 if the macro was running you can find a MsWord document next to the \nSwTestSummary.xls - looking like this:", "type": "Document"}}